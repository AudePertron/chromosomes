{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chromos_crossing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMcXDT7kMUcZpSSM7sVPnkr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AudePertron/chromosomes/blob/main/chromos_crossing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrvN5tjOQiz6",
        "outputId": "ce33b810-8856-4e09-a221-ba99e4ca9a7d"
      },
      "source": [
        "#mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhKbA6Q1Qnkr",
        "outputId": "55fc7212-a2da-4f7e-c715-838c43264e4f"
      },
      "source": [
        "cd gdrive/MyDrive/chromos/base_donnees/ChromSeg/region-guided\\ UNet++\n",
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/chromos/base_donnees/ChromSeg/region-guided UNet++\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noLSEbJXVsFf"
      },
      "source": [
        "#loss.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.transforms import transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn, optim\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import Dataset\n",
        "import PIL.Image as Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.transforms import transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn, optim\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.models as models\n",
        "import PIL.Image as Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import copy\n",
        "#from loss import *\n",
        "#from UNet_plus import UNet_plus2 as UNet_plus2\n",
        "#from utils import *\n",
        "import argparse\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9TVTMOsLeEn",
        "outputId": "bd448129-103f-4df8-b572-51bcddcd8fcb"
      },
      "source": [
        "#check GPU\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 8342392324163919912, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 11345264640\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 12732197337835394920\n",
              " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TwFKBx8yv5w"
      },
      "source": [
        "#initialize model\n",
        "#Unet_plus.py\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.transforms import transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    # The convolutional layer: conv3-relu-conv3-relu\n",
        "    def __init__(self, in_ch, mid_ch, out_ch):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, mid_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(mid_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.conv(input)\n",
        "\n",
        "\n",
        "class UNet_plus2(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_ch=3, out_ch=1):\n",
        "        super(UNet_plus2, self).__init__()\n",
        "        self.n_channels = in_ch\n",
        "        self.n_classes = out_ch\n",
        "        n1 = 64\n",
        "        filters = [n1, n1 * 2, n1 * 4, n1 * 8]\n",
        "\n",
        "        # Encoder: U-Net\n",
        "        #self.conv0_0 = nn.Sequential(\n",
        "        #    nn.Conv2d(in_ch, filters[0], kernel_size=7, stride=1, padding=3,\n",
        "        #         bias=False),\n",
        "        #    nn.BatchNorm2d(filters[0]),\n",
        "        #    nn.ReLU(inplace=True)\n",
        "        #)\n",
        "        self.conv0_0 = DoubleConv(self.n_channels, filters[0], filters[0])\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, ceil_mode=True)\n",
        "        self.conv1_0= DoubleConv(filters[0], filters[1], filters[1])\n",
        "        self.conv2_0= DoubleConv(filters[1], filters[2], filters[2])\n",
        "        self.conv3_0= DoubleConv(filters[2], filters[3], filters[3])\n",
        "\n",
        "        # Upsample layer(Deconv)\n",
        "        self.up1_0 = nn.ConvTranspose2d(filters[1], filters[0], 2, stride=2)\n",
        "        self.up2_0 = nn.ConvTranspose2d(filters[2], filters[1], 2, stride=2)\n",
        "        self.up3_0 = nn.ConvTranspose2d(filters[3], filters[2], 2, stride=2)\n",
        "        self.up1_1 = nn.ConvTranspose2d(filters[1], filters[0], 2, stride=2)\n",
        "        self.up2_1 = nn.ConvTranspose2d(filters[2], filters[1], 2, stride=2)\n",
        "        self.up1_2 = nn.ConvTranspose2d(filters[1], filters[0], 2, stride=2)\n",
        "\n",
        "        # Mid Layer\n",
        "        self.conv0_1 = DoubleConv(filters[0]*2, filters[0], filters[0]) \n",
        "        self.conv1_1 = DoubleConv(filters[1]*2, filters[1], filters[1])\n",
        "        self.conv2_1 = DoubleConv(filters[2]*2, filters[2], filters[2])\n",
        "\n",
        "        self.conv0_2 = DoubleConv(filters[0]*2, filters[0], filters[0])\n",
        "        self.conv1_2 = DoubleConv(filters[1]*2, filters[1], filters[1])\n",
        "\n",
        "        self.conv0_3 = DoubleConv(filters[0]*2, filters[0], filters[0])\n",
        "\n",
        "        # attention\n",
        "        # self.attention0 = ContourAttention(filters[0])\n",
        "        # self.attention1 = ContourAttention(filters[1])\n",
        "        \n",
        "        self.contour = nn.Sequential(\n",
        "            nn.Conv2d(filters[0] * 2, filters[0], kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(filters[0], filters[0], kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(filters[0], out_ch, 1)\n",
        "        )\n",
        "        self.final = nn.Sequential(\n",
        "            nn.Conv2d(filters[0], filters[0], kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(filters[0], out_ch, 1)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x0_0 = self.conv0_0(x)\n",
        "        p = self.pool(x0_0)\n",
        "        x1_0 = self.conv1_0(p)\n",
        "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
        "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
        "\n",
        "        x0_1 = self.conv0_1(torch.cat([x0_0, self.up1_0(x1_0)], 1)) + x0_0\n",
        "        x1_1 = self.conv1_1(torch.cat([x1_0, self.up2_0(x2_0)], 1))\n",
        "        x2_1 = self.conv2_1(torch.cat([x2_0, self.up3_0(x3_0)], 1))\n",
        "        \n",
        "        x0_2 = self.conv0_2(torch.cat([x0_1, self.up1_1(x1_1)], 1)) + x0_1\n",
        "        # x1_2 = self.conv1_2(torch.cat([self.attention1(x1_1, x1_0), self.up2_1(x2_1)], 1))\n",
        "        x1_2 = self.conv1_2(torch.cat([x1_0, self.up2_1(x2_1)], 1))\n",
        "        \n",
        "        # x0_3 = self.conv0_3(torch.cat([self.attention0(x0_2, x0_0), self.up1_2(x1_2)], 1))\n",
        "        x0_3 = self.conv0_3(torch.cat([x0_0, self.up1_2(x1_2)], 1))\n",
        "        \n",
        "        contour = self.contour(torch.cat([x0_1, x0_2], dim=1))\n",
        "        output = self.final(x0_3)\n",
        "\n",
        "        return self.sigmoid(output), self.sigmoid(contour)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nooJXq52mdqX",
        "outputId": "d34fea80-2e90-476b-cb85-6e910b8a918c"
      },
      "source": [
        "#load model\n",
        "model = UNet_plus2(3, 1)\n",
        "model.load_state_dict(torch.load('/content/gdrive/MyDrive/chromos/base_donnees/ChromSeg/region-guided UNet++/model.pth'))\n",
        "model.eval()\n",
        "print(\"model loaded\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "Pmmt04p3yXZX",
        "outputId": "c744960e-4a98-4cc5-8d6a-26c35ad0401d"
      },
      "source": [
        "image = Image.open('/content/gdrive/MyDrive/chromos/base_donnees/outputs/roi29.jpg')\n",
        "image.shape()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-0577b0f32c2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/chromos/base_donnees/outputs/roi29.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'JpegImageFile' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn2dSHp8RmRv"
      },
      "source": [
        "#make ready test image\n",
        "image = Image.open('/content/gdrive/MyDrive/chromos/base_donnees/ChromSeg/crossing_partition/img/1.png')\n",
        "#image = Image.open('/content/gdrive/MyDrive/chromos/base_donnees/outputs/roi29.jpg')\n",
        "x_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "image_test = x_transforms(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUNhdIipypVj",
        "outputId": "a136931a-d76f-42a0-9e28-48f69cea149a"
      },
      "source": [
        "image_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ARlbdgXpwkg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6be0324-1d9e-4378-edfd-27377c8567a0"
      },
      "source": [
        "#pred_test = model(image_test[None, ...])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LppIJ8Gef5yD"
      },
      "source": [
        "IMAGE_PATH = '/content/gdrive/MyDrive/chromos/base_donnees/ChromSeg/crossing_partition/img'\n",
        "OVERLAP_PATH = '/content/gdrive/MyDrive/chromos/base_donnees/ChromSeg/crossing_partition/crossing'\n",
        "OTHER_PATH = '/content/gdrive/MyDrive/chromos/base_donnees/ChromSeg/crossing_partition/chromosome'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQcVx6F_uva3"
      },
      "source": [
        "#predict \n",
        "n = \"coucou\"\n",
        "with torch.no_grad():\n",
        "  y = model(image_test[None, ...])\n",
        "  y_pred_0 = torch.squeeze(y[0]).numpy()\n",
        "  y_pred = np.zeros((256,256))\n",
        "  y_pred[y_pred_0 > 0.5] = 1.0\n",
        "  y_2_0 = torch.squeeze(y[1]).numpy()\n",
        "  y_2 = np.zeros((256,256))\n",
        "  y_2[y_2_0 > 0.5] = 1.0\n",
        "  output1 = np.reshape(y_pred * 255,(256,256))\n",
        "  output2 = np.reshape(y_2 * 255,(256,256))\n",
        "\n",
        "  x_image = torch.squeeze(image_test).numpy()\n",
        "  image = np.dstack((x_image[0,...]*255, x_image[1,...]*255, x_image[2,...]*255))\n",
        "\n",
        "  cv2.imwrite(OVERLAP_PATH + '/' + str(n) + \".png\", output1)\n",
        "\n",
        "  cv2.imwrite(OTHER_PATH + '/' + str(n) + \".png\", output2)\n",
        "  cv2.imwrite(IMAGE_PATH + '/' + str(n) + \".png\", image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "ned2whsHuTK-",
        "outputId": "39d4141b-6077-4552-85df-599756293f13"
      },
      "source": [
        "#visualize\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(output2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1861087310>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "3pJIsyoBZJdc",
        "outputId": "14ab50e7-10cb-4efd-c1d0-01dc633a42df"
      },
      "source": [
        "plt.imshow(output1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1860f57a10>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06NG-3Pug52a",
        "outputId": "0a4e1739-b210-4aee-f7c5-097783e585ea"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdataset\u001b[0m/              main.py               OVERLAP_PATH0.png       utils.py\n",
            "IMAGE_PATH0.png       model.pth             OVERLAP_PATHcoucou.png\n",
            "IMAGE_PATHcoucou.png  OTHER_PATH0.png       \u001b[01;34m__pycache__\u001b[0m/\n",
            "loss.py               OTHER_PATHcoucou.png  UNet_plus.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yhg1LHwemXu"
      },
      "source": [
        "## Crossing partitions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2y0xQ3BZXlB"
      },
      "source": [
        "#utils.py\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import copy\n",
        "from skimage import io\n",
        "import math\n",
        "import copy\n",
        "import time\n",
        "import os\n",
        "\n",
        "def adjacent(array, x, y, size = 10):\n",
        "    # 使用这个函数来存储一个像素点的邻近点到一个列表中\n",
        "    adjacent = []\n",
        "    for i in range(-size,size+1):\n",
        "        for j in range(-size,size+1):\n",
        "            if x+i >= 0 and y+j>=0 and x+i < array.shape[0] and y+j < array.shape[1]:\n",
        "                adjacent.append((x+i, y+j))\n",
        "    return adjacent\n",
        "\n",
        "def dilated_adjacent(array, overlapping_x, overlapping_y, size = 15):\n",
        "    global _adj\n",
        "    tmp = np.zeros(array.shape)\n",
        "    tmp[overlapping_x, overlapping_y] = array[overlapping_x, overlapping_y].copy()\n",
        "    \n",
        "    kernel = np.ones((size, size), np.uint8)\n",
        "    tmp = cv2.dilate(tmp, kernel, iterations=1)\n",
        "    tmp[overlapping_x, overlapping_y] -= array[overlapping_x, overlapping_y]\n",
        "    \n",
        "    # 测试用\n",
        "#     _adj.append(tmp)\n",
        "    \n",
        "    xs, ys = np.where(tmp > 0)\n",
        "    ret = []\n",
        "    for x, y in zip(xs, ys):\n",
        "        ret.append((x, y))\n",
        "    return ret\n",
        "    \n",
        "# 两个函数用来计算两个点连成射线后的点集中是否有可以match的区域\n",
        "def line_detect(img, point1, point2, sign):\n",
        "    point1_x, point1_y = point1\n",
        "    point2_x, point2_y = point2\n",
        "    if point1_x != point2_x:\n",
        "        k = float((point1_y - point2_y)/(point1_x - point2_x))\n",
        "        b = ((point1_y - k*point1_x)+(point2_y - k*point2_x))/2\n",
        "        for x in range(img.shape[1]):\n",
        "            y = int(k*x+b)\n",
        "            if y>=0 and y<img.shape[0]:\n",
        "                if img[x,y] == 1 or img[x,y] == -1 or img[x,y] == sign:\n",
        "                    continue\n",
        "                else:\n",
        "                    return img[x,y]\n",
        "                \n",
        "        for y in range(img.shape[0]):\n",
        "            x = int((y-b)/k)\n",
        "            if x>=0 and x<img.shape[1]:\n",
        "                if img[x,y] == 1 or img[x,y] == -1 or img[x,y] == sign:\n",
        "                    continue\n",
        "                else:\n",
        "                    return img[x,y]\n",
        "    else:\n",
        "        x = point1_x\n",
        "        for y in range(img.shape[0]):\n",
        "            if img[x,y] == 1 or img[x,y] == -1 or img[x,y] == sign:\n",
        "                    continue\n",
        "            else:\n",
        "                return img[x,y] \n",
        "    return 0\n",
        "\n",
        "def ray_detect(img, point_start, point_end, sign):\n",
        "    point1_x, point1_y = point_start\n",
        "    point2_x, point2_y = point_end\n",
        "    direction_x = point2_x - point1_x\n",
        "    direction_y = point2_y - point1_y\n",
        "    if point1_x != point2_x:\n",
        "        k = float((point1_y - point2_y)/(point1_x - point2_x))\n",
        "        b = ((point1_y - k*point1_x)+(point2_y - k*point2_x))/2\n",
        "        if direction_x > 0:\n",
        "            for x in range(point2_x, img.shape[1]):\n",
        "                y = int(k*x+b)\n",
        "                if y>=0 and y<img.shape[0]:\n",
        "                    if img[x,y] == 1 or img[x,y] == -1 or img[x,y] == sign:\n",
        "                        continue\n",
        "                    else:\n",
        "                        return int(img[x,y])\n",
        "        if direction_x < 0:\n",
        "            for x in range(0, point2_x):\n",
        "                y = int(k*x+b)\n",
        "                if y>=0 and y<img.shape[0]:\n",
        "                    if img[x,y] == 1 or img[x,y] == -1 or img[x,y] == sign:\n",
        "                        continue\n",
        "                    else:\n",
        "                        return int(img[x,y])\n",
        "        if direction_y > 0: \n",
        "            for y in range(point2_y, img.shape[0]):\n",
        "                x = int((y-b)/k)\n",
        "                if x>=0 and x<img.shape[1]:\n",
        "                    if img[x,y] == 1 or img[x,y] == -1 or img[x,y] == sign:\n",
        "                        continue\n",
        "                    else:\n",
        "                        return int(img[x,y])\n",
        "        if direction_y < 0: \n",
        "            for y in range(0, point2_y):\n",
        "                x = int((y-b)/k)\n",
        "                if x>=0 and x<img.shape[1]:\n",
        "                    if img[x,y] == 1 or img[x,y] == -1 or img[x,y] == sign:\n",
        "                        continue\n",
        "                    else:\n",
        "                        return int(img[x,y])\n",
        "    else:\n",
        "        x = point1_x\n",
        "        for y in range(img.shape[0]):\n",
        "            if img[x,y] == 1 or img[x,y] == -1 or img[x,y] == sign:\n",
        "                continue\n",
        "            else:\n",
        "                return int(img[x,y])\n",
        "    return 0\n",
        "\n",
        "class UnionFind(object):\n",
        "    def __init__(self, classes):\n",
        "        self.__parent = np.concatenate([np.array([0, 1]), classes])\n",
        "    def find(self, x):\n",
        "        if x == self.__parent[x]:\n",
        "            return x\n",
        "        else:\n",
        "            self.__parent[x] = self.find(self.__parent[x])\n",
        "            return self.__parent[x]\n",
        "    \n",
        "    def union(self, x, y):\n",
        "        px, py = self.find(x), self.find(y)\n",
        "        if (px != py):\n",
        "            self.__parent[px] = py\n",
        "\n",
        "def crossing_reconstruct(image, overlapped, non_overlapped):\n",
        "    ### watershed for crossing areas\n",
        "    kernel = np.ones((1,1),np.uint8)\n",
        "    opening_crossing = cv2.morphologyEx(overlapped,cv2.MORPH_OPEN, kernel)\n",
        "    # sure foreground area\n",
        "    sure_fg_crossing = cv2.erode(opening_crossing,kernel,iterations=1)\n",
        "    # sure background area\n",
        "    sure_bg_crossing = cv2.dilate(opening_crossing,kernel,iterations=1)\n",
        "    crossing_edge = cv2.subtract(sure_bg_crossing,sure_fg_crossing)\n",
        "\n",
        "    # Marker labelling\n",
        "    ret, markers = cv2.connectedComponents(sure_fg_crossing)\n",
        "    # Add one to all labels so that sure background is not 0, but 1\n",
        "    markers = markers + 1\n",
        "    # Now, mark the region of unknown with zero\n",
        "    markers[crossing_edge == 1] = 0\n",
        "    markers_crossing = cv2.watershed(image, markers)\n",
        "    \n",
        "    # overlapping_class列表存储crossing有的类别，例如，有两个crossing重叠区域，overlapping_class列表中就有两个元素\n",
        "    overlapping_class = [i for i in range(2, np.max(markers_crossing)+1)]\n",
        "    overlapping_x_class = {}\n",
        "    overlapping_y_class = {}\n",
        "    \n",
        "    # iterate through all markers values\n",
        "    for i in overlapping_class:\n",
        "        overlapping_x_class[i], overlapping_y_class[i] = np.where(markers == i)\n",
        "\n",
        "    # overlapping_center_class是一个字典，存储每个crossing区域的中点坐标\n",
        "    overlapping_center_class = {}\n",
        "    for i in overlapping_class:\n",
        "        overlapping_center_class[i] = (int(np.mean(overlapping_x_class[i])),int(np.mean(overlapping_y_class[i])))\n",
        "\n",
        "    # overlapped_areas是crossing区域和相邻size = k的区域的点集，k可以在adjacent函数中调整\n",
        "    overlapped_areas = {}\n",
        "    for i in overlapping_class:\n",
        "        overlapped_areas[i] = dilated_adjacent(overlapped, overlapping_x_class[i], overlapping_y_class[i],\n",
        "                                   size = 9)\n",
        "#         radius = int(np.sqrt(len(markers_crossing[markers_crossing == i]) / 2.0))\n",
        "#         overlapped_areas[i] = adjacent(overlapped, overlapping_center_class[i][0], overlapping_center_class[i][1],\n",
        "#                                        size = radius)\n",
        "    \n",
        "    # 对non-overlapping的部分watershed处理\n",
        "    ### noise removal\n",
        "    kernel = np.ones((3,3),np.uint8)\n",
        "    opening = cv2.morphologyEx(non_overlapped, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # sure foreground area\n",
        "    sure_fg = cv2.erode(opening,kernel,iterations=1)\n",
        "    # sure background area\n",
        "    sure_bg = cv2.dilate(opening,kernel,iterations=2)\n",
        "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "\n",
        "    # Marker labelling\n",
        "    hole = sure_fg.copy()\n",
        "    cv2.floodFill(hole,None,(0,0),255) # 找到洞孔\n",
        "    hole = cv2.bitwise_not(hole)\n",
        "    ret, markers = cv2.connectedComponents(hole)\n",
        "\n",
        "    # Add one to all labels so that sure background is not 0, but 1\n",
        "    markers = markers + 1\n",
        "    # Now, mark the region of unknown with zero\n",
        "    markers[unknown == 1] = 0\n",
        "    # watershed\n",
        "    markers = cv2.watershed(image, markers)\n",
        "    class_num = np.max(markers)\n",
        "    non_overlapping_class = np.arange(2, class_num + 1)\n",
        "\n",
        "    # overlapping_match_nonoverlapping是一个字典，用来存储和crossing区域相邻的non-overlapping区域的编号标记\n",
        "    overlapping_match_nonoverlapping = {}\n",
        "    for i in overlapping_class:\n",
        "        overlapping_match_nonoverlapping[i] = set()\n",
        "        for j in overlapped_areas[i]:\n",
        "            if markers[j[0], j[1]] > 1:\n",
        "                overlapping_match_nonoverlapping[i].add(markers[j[0], j[1]])  \n",
        "\n",
        "    # overlapping_match_nonoverlapping_center用来存储和crossing区域相邻的non-overlapping子区域的区域中心坐标\n",
        "    overlapping_match_nonoverlapping_center = {}\n",
        "    for i in overlapping_match_nonoverlapping:\n",
        "        adj_x, adj_y = zip(*overlapped_areas[i])\n",
        "        adj_x, adj_y = np.array(adj_x), np.array(adj_y)\n",
        "\n",
        "        overlapping_match_nonoverlapping_center[i] = {}\n",
        "        for k in overlapping_match_nonoverlapping[i]:\n",
        "            k_adj_x = adj_x[np.where(markers[adj_x, adj_y] == k)[0]]\n",
        "            k_adj_y = adj_y[np.where(markers[adj_x, adj_y] == k)[0]]\n",
        "            c = (int(np.mean(k_adj_x)), int(np.mean(k_adj_y)))\n",
        "    #             temp_x, temp_y = np.where(markers == k)\n",
        "    #             c = (int(np.mean(temp_x)),int(np.mean(temp_y)))\n",
        "            overlapping_match_nonoverlapping_center[i][k] = c\n",
        "\n",
        "    # UnionFind for combination\n",
        "    uf = UnionFind(non_overlapping_class)\n",
        "\n",
        "    output = copy.deepcopy(markers)\n",
        "    for i in overlapping_match_nonoverlapping:\n",
        "        temp_area = np.ones(markers.shape)\n",
        "        for (x, y) in overlapped_areas[i]:\n",
        "            temp_area[x, y] = markers[x, y]\n",
        "\n",
        "        # Ray detect of non-overlapping part in a cycle\n",
        "        for j in overlapping_match_nonoverlapping_center[i]:\n",
        "            tag = ray_detect(temp_area, overlapping_match_nonoverlapping_center[i][j], overlapping_center_class[i], j)\n",
        "            if tag in overlapping_match_nonoverlapping_center[i]:\n",
        "                uf.union(tag, j)\n",
        "\n",
        "    chromosome = {}  # dictionary key is non-overlap class for chromosome, value is overlapping region class\n",
        "\n",
        "    for tag in non_overlapping_class:\n",
        "        output[output == tag] = uf.find(tag)\n",
        "        chromosome[uf.find(tag)] = []\n",
        "\n",
        "    for i in overlapping_class:\n",
        "        for j in non_overlapping_class:\n",
        "            if j in overlapping_match_nonoverlapping[i] and i not in chromosome[uf.find(j)]:\n",
        "                chromosome[uf.find(j)].append(i)  \n",
        "\n",
        "    cp_image = []\n",
        "    for i in chromosome:\n",
        "        mask = np.zeros(output.shape)\n",
        "        mask[(output == i)] = 1\n",
        "        for j in chromosome[i]:\n",
        "            mask[markers_crossing == j] = 1\n",
        "        cp_image.append(mask)\n",
        "        \n",
        "    return cp_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixLs5-CBewWc"
      },
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import copy\n",
        "from skimage import io\n",
        "import math\n",
        "import copy\n",
        "import time\n",
        "from utils import *\n",
        "\n",
        "IMG_SIZE = 256\n",
        "\n",
        "OUTPUT_PATH = '/content/gdrive/MyDrive/chromos/base_donnees/ChromSeg/crossing_partition/output'\n",
        "FILE_NUM = 2\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    for i in range(1, FILE_NUM + 1):\n",
        "        image = cv2.imread(os.path.join(IMAGE_PATH, str(i)+'.png'))\n",
        "        overlapped = cv2.imread(os.path.join(OVERLAP_PATH, str(i)+'.png'), 0)\n",
        "        foreground = cv2.imread(os.path.join(OTHER_PATH, str(i)+'.png'), 0)\n",
        "        non_overlapped = np.zeros(overlapped.shape)\n",
        "        # kernel = np.ones((1,1),np.uint8)\n",
        "        # overlapped = cv2.dilate(overlapped,kernel,iterations=1)\n",
        "        overlapped[overlapped == 255] = 1\n",
        "        non_overlapped[(overlapped == 0) & (foreground == 255)] = 1   # calculate non-overlapping mask \n",
        "\n",
        "        output = crossing_reconstruct(image, overlapped, non_overlapped)\n",
        "\n",
        "        output_path = os.path.join(OUTPUT_PATH, str(i))\n",
        "        if not os.path.exists(output_path):\n",
        "            os.mkdir(output_path)\n",
        "\n",
        "        cv2.imwrite(os.path.join(output_path, \"crossing_\" + str(i)+\".png\"), image)\n",
        "\n",
        "        try:\n",
        "            gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "            num = 0\n",
        "            for mask in output:\n",
        "                img = copy.deepcopy(gray)\n",
        "                new_mask = np.zeros((IMG_SIZE, IMG_SIZE))\n",
        "                for i in range(0, IMG_SIZE):\n",
        "                    for j in range(0, IMG_SIZE):\n",
        "                        if(mask[i,j] == 1):\n",
        "                            for x in range(-1,2):\n",
        "                                for y in range(-1,2):\n",
        "                                    try:\n",
        "                                        new_mask[i+x,j+y] = 1\n",
        "                                    except:\n",
        "                                        continue\n",
        "\n",
        "                img[(new_mask == 0)] = 255\n",
        "                cv2.imwrite(os.path.join(output_path, str(num)+\".png\"), img)\n",
        "                num += 1\n",
        "        except:\n",
        "            raise \"error(fail to partition)\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}